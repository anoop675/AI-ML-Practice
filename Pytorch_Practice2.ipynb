{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## ESC708 Pytorch Basics"
      ],
      "metadata": {
        "id": "d8GwLiJIyUK5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kUW-GQ-qx5Vn"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Tensor Operations and Dimensions"
      ],
      "metadata": {
        "id": "RidM4diwyY6v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correct matrix multiplication: (2x3) * (3x4) = (2x4)\n",
        "# (d x n) @ (n x f) = (d x f)\n",
        "# torch.matmul is equivalent to @\n",
        "a = torch.randn(2, 3)\n",
        "b = torch.randn(3, 4)\n",
        "c = torch.matmul(a, b)  # Works\n",
        "c"
      ],
      "metadata": {
        "id": "3kZtvyKyylyV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b3077f7-3a87-4613-d2d7-1519f7a88bad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.4276,  1.2581, -1.5774, -1.2810],\n",
              "        [ 0.0693, -0.7371, -0.7794,  2.2299]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Incorrect matrix multiplication: mismatched dimensions (2x3) * (2x4)\n",
        "# https://pytorch.org/docs/stable/generated/torch.matmul.html\n",
        "c = torch.matmul(a, b.T)  # Should raise an error"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "yJdnDwAdyrww",
        "outputId": "adae3856-5f62-4468-fb51-9a3211bfc843"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 shapes cannot be multiplied (2x3 and 4x3)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-98737e4c2cac>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Incorrect matrix multiplication: mismatched dimensions (2x3) * (2x4)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# https://pytorch.org/docs/stable/generated/torch.matmul.html\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Should raise an error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (2x3 and 4x3)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# what about when some dimensions (excluding the final 2) do not match ?\n",
        "a = torch.randn(10, 2, 3, 4)\n",
        "b = torch.randn(10, 3, 4, 5)\n",
        "a @ b # error"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "6UN7HmcGVG4D",
        "outputId": "4ca5c114-99af-472c-a246-88505a21ddfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 1",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-684e07983994>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 1"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Can we also do matmul for n-dim matrices? yes! - but the dimensions need to match\n",
        "a = torch.randn(10, 3, 4)\n",
        "b = torch.randn(5, 4, 5)\n",
        "c = torch.matmul(a, b)\n",
        "\n",
        "# (3x4)@(4x5)=(3x5)\n",
        "c.size()  # torch.Size([10, 3, 5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "oBzwDym50RK6",
        "outputId": "ea84c3c6-a7b5-4592-84fe-01db88b6d810"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "The size of tensor a (10) must match the size of tensor b (5) at non-singleton dimension 0",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-becd32daa4ee>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# (3x4)@(4x5)=(3x5)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (10) must match the size of tensor b (5) at non-singleton dimension 0"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Does the order matter in torch.matmul() ? Yes\n",
        "c = torch.matmul(b, a)\n",
        "c.size()  # Expected Error.."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "2mjP9wqE6xOO",
        "outputId": "1b225e1e-23e6-4418-fba9-18b2fd7a1ab1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 shapes cannot be multiplied (4x5 and 3x4)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-d47348533935>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Does the order matter in torch.matmul() ?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# torch.Size([10, 3, 5])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (4x5 and 3x4)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Element-wise multiplication (Hadamart Product) - How does this differ from matrix multiplication ?\n",
        "\n",
        "# Two tensors of the same shape (2x3)\n",
        "a = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
        "b = torch.tensor([[7, 8, 9], [10, 11, 12]])\n",
        "\n",
        "# Element-wise multiplication (same shape)\n",
        "element_wise = torch.mul(a,b)  # Each element is multiplied with the corresponding element in the other tensor\n",
        "print(\"Element-wise multiplication:\\n\", element_wise)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6UV3BXPSyu30",
        "outputId": "34c6cacf-d80f-4bfe-f955-ea86212210cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Element-wise multiplication:\n",
            " tensor([[ 7, 16, 27],\n",
            "        [40, 55, 72]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# You can also do this with tensors of different shapes as long as they are broadcastable.\n",
        "# Broadcasting automatically expands the smaller tensor so that both tensors have compatible shapes:\n",
        "# Broadcastable shapes: (2x3) * (1x3)\n",
        "a = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
        "b = torch.tensor([[7, 8, 9], ])  # Shape (1x3) can be broadcast to (2x3)\n",
        "\n",
        "element_wise_broadcast = torch.mul(a,b)\n",
        "print(\"Element-wise multiplication with broadcasting:\\n\", element_wise_broadcast)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQRzH-jvzWhb",
        "outputId": "a6f7dd5f-0c08-4d0f-be97-0fd47c9c8095"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Element-wise multiplication with broadcasting:\n",
            " tensor([[ 7, 16, 27],\n",
            "        [28, 40, 54]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# More broadcasting examples...\n",
        "a = torch.ones(3, 1)\n",
        "b = torch.zeros(3)\n",
        "\n",
        "# torch.ones(3,3) + torch.zeros(3,3)\n",
        "\n",
        "# Correct broadcasting\n",
        "c = a + b  # Shape: (3, 3), works\n",
        "print(c)\n",
        "\n",
        "# Incorrect broadcasting (mismatched dimensions)\n",
        "b = torch.ones(4)\n",
        "# a: torch.ones(3,4), b torch.ones(3,4)\n",
        "c = a + b\n",
        "print(c)\n"
      ],
      "metadata": {
        "id": "49q0rpdx2MSM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35efa6bf-0ea5-4356-bf57-c7652f588651"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.]])\n",
            "tensor([[2., 2., 2., 2.],\n",
            "        [2., 2., 2., 2.],\n",
            "        [2., 2., 2., 2.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Rearranging dimensions\n",
        "\n",
        "# Create a 3D tensor of shape (2, 3, 4)\n",
        "a = torch.randn(2, 3, 4)\n",
        "\n",
        "# Transpose dimensions 1 and 2 (shape becomes (2, 4, 3))\n",
        "a_transposed = a.transpose(1, 2)\n",
        "print(\"Original shape:\", a.shape)  # (2, 3, 4)\n",
        "print(\"After transpose(1, 2):\", a_transposed.shape)  # (2, 4, 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDhkknnEzh_d",
        "outputId": "e9d58756-0d57-40f2-cb59-14187933a171"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original shape: torch.Size([2, 3, 4])\n",
            "After transpose(1, 2): torch.Size([2, 4, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.randn(2, 3, 4)\n",
        "a.T # note user warning. dont use .T for anything other than 2 dims."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMcXok07ZttF",
        "outputId": "432fd4b1-4652-49da-d246-fcf9f62ec29b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-ea67e2de674e>:2: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3683.)\n",
            "  a.T\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 1.0655, -0.0180],\n",
              "         [ 1.7758,  0.1558],\n",
              "         [ 2.2286,  0.0860]],\n",
              "\n",
              "        [[ 2.5845, -0.3120],\n",
              "         [ 0.3207,  0.7466],\n",
              "         [-0.6242,  0.4851]],\n",
              "\n",
              "        [[-0.8223, -1.1351],\n",
              "         [ 0.3441, -1.4254],\n",
              "         [-2.1659, -0.4221]],\n",
              "\n",
              "        [[-0.0251,  0.1085],\n",
              "         [-0.5064, -0.2434],\n",
              "         [-1.0043, -0.6664]]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Is this equivalent to .T?  Yes, but .T only works for 2D tensors.\n",
        "\n",
        "# Create a 2D tensor (matrix) of shape (2, 3)\n",
        "a = torch.randn(2, 3)\n",
        "\n",
        "# Use .T to transpose the matrix (shape becomes (3, 2))\n",
        "a_transposed = a.T\n",
        "print(\"Original shape:\", a.shape)  # (2, 3)\n",
        "print(\"After .T:\", a_transposed.shape)  # (3, 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7duXkgDo1Jpg",
        "outputId": "1670b78f-dd4a-4711-a0ac-2af08b9cd9fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original shape: torch.Size([2, 3])\n",
            "After .T: torch.Size([3, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshaping a tensor\n",
        "\n",
        "# Create a tensor of shape (2, 6)\n",
        "a = torch.randn(2, 6) # 12 values\n",
        "\n",
        "# Reshape it to (3, 4)\n",
        "reshaped_a = a.reshape(3, 4)\n",
        "print(\"Original shape:\", a.shape)  # (2, 6)\n",
        "print(\"Reshaped shape:\", reshaped_a.shape)  # (3, 4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LEen7TPK1RkG",
        "outputId": "251bd489-2225-443c-f0b2-9d1353ed3e29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original shape: torch.Size([2, 6])\n",
            "Reshaped shape: torch.Size([3, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# What does -1 mean in reshape? This is handy because pytorch can infer the correct size.\n",
        "\n",
        "# Create a tensor of shape (2, 3, 4) - 24 elements in total\n",
        "a = torch.randn(2, 3, 4)\n",
        "print(\"Original shape:\", a.shape)  # (2, 3, 4)\n",
        "\n",
        "# Reshape to (6, -1): PyTorch will infer the second dimension (should be 4)\n",
        "reshaped_a = a.reshape(6, -1)\n",
        "print(\"Reshaped to (6, -1):\", reshaped_a.shape)  # (6, 4)\n",
        "\n",
        "# Reshape to (-1, 8): PyTorch will infer the first dimension (should be 3)\n",
        "reshaped_b = a.reshape(-1, 8)\n",
        "print(\"Reshaped to (-1, 8):\", reshaped_b.shape)  # (3, 8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CAMdFd-z1pUo",
        "outputId": "ec19c696-1a7d-4d67-f634-d2048ba22ba1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original shape: torch.Size([2, 3, 4])\n",
            "Reshaped to (6, -1): torch.Size([6, 4])\n",
            "Reshaped to (-1, 8): torch.Size([3, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "x = torch.matmul(1,b)\n",
        "y = torch.mat(4,3)\n",
        "# In place operations. Why do we need them? - Memory efficient\n",
        "\n",
        "# Create a tensor\n",
        "x = torch.tensor([1.0, 2.0, 3.0])\n",
        "\n",
        "# In-place addition: x = x + 1\n",
        "x += torch.tensor([1.0, 0.0, 3.0])\n",
        "#\n",
        "x = x + torch.tensor([1.0, 0.0, 3.0])\n",
        "print(\"After in-place addition:\", x)  # tensor([2., 3., 4.])\n",
        "\n",
        "# In-place multiplication: x = x * 2\n",
        "x *= 2\n",
        "print(\"After in-place multiplication:\", x)  # tensor([ 4.,  6.,  8.])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1eF48baL4_a3",
        "outputId": "a13ebc47-4732-4530-d81b-544c1e7f37c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After in-place addition: tensor([3., 2., 9.])\n",
            "After in-place multiplication: tensor([ 6.,  4., 18.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a 2D tensor\n",
        "x = torch.tensor([[1.0, 2.0], [3.0, 4.0]])\n",
        "\n",
        "# Mean of all elements in the tensor\n",
        "mean_all = torch.mean(x)\n",
        "print(\"Mean of all elements:\", mean_all)  # tensor(2.5000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hP_Wy06p45r2",
        "outputId": "b311774b-f83e-427e-9dfd-1c967ef82e71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean of all elements: tensor(2.5000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mean along dimension 0 (rows)\n",
        "mean_dim0 = torch.mean(x, dim=0)\n",
        "print(\"Mean along dimension 0 (rows):\", mean_dim0)  # tensor([2., 3.])\n",
        "\n",
        "# Mean along dimension 1 (columns)\n",
        "mean_dim1 = torch.mean(x, dim=1)\n",
        "print(\"Mean along dimension 1 (columns):\", mean_dim1)  # tensor([1.5000, 3.5000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hfIDNoSz5-3G",
        "outputId": "5607159e-2653-49e4-d9ff-c5b3e12144b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean along dimension 0 (rows): tensor([2., 3.])\n",
            "Mean along dimension 1 (columns): tensor([1.5000, 3.5000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensor Initialisation !\n",
        "\n",
        "# Zero tensor\n",
        "x_zeros = torch.zeros(3, 3)  # 3x3 tensor filled with zeros\n",
        "\n",
        "# One tensor\n",
        "x_ones = torch.ones(3, 3)  # 3x3 tensor filled with ones\n",
        "\n",
        "# Random tensor (normal distribution)\n",
        "x_random = torch.randn(3, 3)\n",
        "\n",
        "# Tensor with values from a range\n",
        "x_range = torch.arange(0, 10, step=2)  # 0, 2, 4, 6, 8\n",
        "\n",
        "# Tensor filled with a constant value\n",
        "x_full = torch.full((3, 3), 7)  # 3x3 tensor filled with the value 7"
      ],
      "metadata": {
        "id": "SZyV31ZX9Bj4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. The model class, nn.Module()"
      ],
      "metadata": {
        "id": "8iP6ujw_2epl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a simple model\n",
        "class SimpleModel(nn.Module):\n",
        "    # Here we can define class variables\n",
        "    def __init__(self):\n",
        "        # Call the parent class (nn.Module) constructor to initialize the necessary PyTorch internals\n",
        "        super().__init__()\n",
        "        # here you define some class variables e.g weights, layers that..\n",
        "        # that can be accessed in self.forward()\n",
        "        self.y = torch.randn([10, 1])\n",
        "\n",
        "    # forward() is where we compute an output from our input\n",
        "    def forward(self, x):\n",
        "        z = torch.matmul(self.y, x)\n",
        "        return z\n",
        "\n",
        "# Pass incorrect input shape\n",
        "model = SimpleModel()\n",
        "input_tensor = torch.randn(1, 8)  # Wrong shape (should be 10)\n",
        "output = model(input_tensor)\n",
        "print(output.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDvX1fOd2Ae1",
        "outputId": "9456c63d-79ec-42dc-fdfd-5ac62be3c426"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# What is nn.Module() ?\n",
        "#  https://pytorch.org/docs/stable/generated/torch.nn.Module.html\n",
        "# Base class where we can inherit lots of inbuilt pytorch methods\n",
        "# Useful for neural networks, not necessary for our implementations of LogReg and LinReg\n"
      ],
      "metadata": {
        "id": "fy0aqAY433CH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Autograd"
      ],
      "metadata": {
        "id": "xmhn7LGR8gbX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We have implemented gradient descent from scratch.\n",
        "# In future we'll use pytorch's inbuilt autograd which automatically handles the computation of gradients.\n",
        "\n",
        "x = torch.tensor(2.0, requires_grad=True)  # Requires gradient tracking\n",
        "y = x ** 2  # Some operation\n",
        "y.backward()  # Compute gradients\n",
        "\n",
        "print(x.grad)  # Gradient of y with respect to x: dy/dx = 2*x = 4.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_pkaBkH8iyJ",
        "outputId": "ca11454a-d81b-41cf-c345-31f46be7c550"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(4.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# What about nn.Parameter() ? It registers a tensor as 'trainable'\n",
        "# We can compute gradients for this tensor when performing gradient descent."
      ],
      "metadata": {
        "id": "0Ad6LqrD8ZXR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CustomModel, self).__init__()\n",
        "        # Define a trainable parameter using nn.Parameter\n",
        "        self.weight = nn.Parameter(torch.randn(3, 3))  # A 3x3 trainable weight matrix\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Perform a matrix multiplication with the custom weight\n",
        "        return torch.matmul(x, self.weight)\n",
        "\n",
        "# Instantiate the model\n",
        "model = CustomModel()\n",
        "\n",
        "# Print the trainable parameters of the model\n",
        "print(\"Model parameters:\", list(model.parameters()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TN3b8mWz9YM3",
        "outputId": "6d52d5d3-6725-492c-df32-c38ade99ec66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model parameters: [Parameter containing:\n",
            "tensor([[-1.1739,  1.5373,  0.3063],\n",
            "        [-0.5537, -1.2269,  0.2839],\n",
            "        [-0.5081, -0.4680, -1.3514]], requires_grad=True)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Debugging, Documentation and Error Messages"
      ],
      "metadata": {
        "id": "Ow4WIIdl42Sc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print, Print, Print !\n",
        "\n",
        "# Create two tensors\n",
        "a = torch.randn(3, 4)\n",
        "b = torch.randn(4, 5)\n",
        "\n",
        "# Ensure tensor shapes are compatible before matrix multiplication\n",
        "print(\"Shape of a:\", a.shape)  # Expected shape: (3, 4)\n",
        "print(\"Shape of b:\", b.shape)  # Expected shape: (4, 5)\n",
        "\n",
        "# Matrix multiplication (will succeed)\n",
        "c = torch.matmul(a, b)\n",
        "print(\"Shape of c:\", c.shape)  # Expected shape: (3, 5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1l1N8da6B4G",
        "outputId": "fc7a0e45-f750-4d97-8825-ede4df8fcbe0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of a: torch.Size([3, 4])\n",
            "Shape of b: torch.Size([4, 5])\n",
            "Shape of c: torch.Size([3, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# How to read the documentation ?"
      ],
      "metadata": {
        "id": "4iVBAlbG6nHY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "help(torch.mean)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1Qf7Jj47yYy",
        "outputId": "bdbb2ff4-9f89-46aa-cfd2-70acd07e56c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on built-in function mean in module torch:\n",
            "\n",
            "mean(...)\n",
            "    mean(input, *, dtype=None) -> Tensor\n",
            "    \n",
            "    Returns the mean value of all elements in the :attr:`input` tensor. Input must be floating point or complex.\n",
            "    \n",
            "    Args:\n",
            "        input (Tensor):\n",
            "          the input tensor, either of floating point or complex dtype\n",
            "    \n",
            "    Keyword args:\n",
            "        dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n",
            "            If specified, the input tensor is casted to :attr:`dtype` before the operation\n",
            "            is performed. This is useful for preventing data type overflows. Default: None.\n",
            "    \n",
            "    Example::\n",
            "    \n",
            "        >>> a = torch.randn(1, 3)\n",
            "        >>> a\n",
            "        tensor([[ 0.2294, -0.5481,  1.3288]])\n",
            "        >>> torch.mean(a)\n",
            "        tensor(0.3367)\n",
            "    \n",
            "    .. function:: mean(input, dim, keepdim=False, *, dtype=None, out=None) -> Tensor\n",
            "       :noindex:\n",
            "    \n",
            "    Returns the mean value of each row of the :attr:`input` tensor in the given\n",
            "    dimension :attr:`dim`. If :attr:`dim` is a list of dimensions,\n",
            "    reduce over all of them.\n",
            "    \n",
            "    \n",
            "    If :attr:`keepdim` is ``True``, the output tensor is of the same size\n",
            "    as :attr:`input` except in the dimension(s) :attr:`dim` where it is of size 1.\n",
            "    Otherwise, :attr:`dim` is squeezed (see :func:`torch.squeeze`), resulting in the\n",
            "    output tensor having 1 (or ``len(dim)``) fewer dimension(s).\n",
            "    \n",
            "    \n",
            "    Args:\n",
            "        input (Tensor): the input tensor.\n",
            "        dim (int or tuple of ints): the dimension or dimensions to reduce.\n",
            "        keepdim (bool): whether the output tensor has :attr:`dim` retained or not.\n",
            "    \n",
            "    Keyword args:\n",
            "        dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n",
            "            If specified, the input tensor is casted to :attr:`dtype` before the operation\n",
            "            is performed. This is useful for preventing data type overflows. Default: None.\n",
            "        out (Tensor, optional): the output tensor.\n",
            "    \n",
            "    .. seealso::\n",
            "    \n",
            "        :func:`torch.nanmean` computes the mean value of `non-NaN` elements.\n",
            "    \n",
            "    Example::\n",
            "    \n",
            "        >>> a = torch.randn(4, 4)\n",
            "        >>> a\n",
            "        tensor([[-0.3841,  0.6320,  0.4254, -0.7384],\n",
            "                [-0.9644,  1.0131, -0.6549, -1.4279],\n",
            "                [-0.2951, -1.3350, -0.7694,  0.5600],\n",
            "                [ 1.0842, -0.9580,  0.3623,  0.2343]])\n",
            "        >>> torch.mean(a, 1)\n",
            "        tensor([-0.0163, -0.5085, -0.4599,  0.1807])\n",
            "        >>> torch.mean(a, 1, True)\n",
            "        tensor([[-0.0163],\n",
            "                [-0.5085],\n",
            "                [-0.4599],\n",
            "                [ 0.1807]])\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jw59m5Uc7yzV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}