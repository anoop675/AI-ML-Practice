{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOX6cdKhZqpqRBrLGsYYLwV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":45,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G0cSWmqvM8wn","executionInfo":{"status":"ok","timestamp":1750789078545,"user_tz":-330,"elapsed":76790,"user":{"displayName":"Anoop Senthil","userId":"06035565146580380298"}},"outputId":"df086d75-d1a1-4367-8d08-ee220c30d054"},"outputs":[{"output_type":"stream","name":"stdout","text":["Inputs :\n"," [[0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," ...\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]]\n","---------------\n","Labels :\n"," ['5' '0' '4' ... '4' '5' '6']\n","[False False False ... False  True False]\n","Fold 1\n","Train indices: [19964 19965 19966 ... 59997 59998 59999]\n","Test indices: [    0     1     2 ... 20331 20342 20359]\n","----------------------------------------\n","Fold 2\n","Train indices: [    0     1     2 ... 59997 59998 59999]\n","Test indices: [19964 19965 19966 ... 40088 40125 40127]\n","----------------------------------------\n","Fold 3\n","Train indices: [    0     1     2 ... 40088 40125 40127]\n","Test indices: [39988 39989 39990 ... 59997 59998 59999]\n","----------------------------------------\n","[np.float64(0.95035), np.float64(0.96035), np.float64(0.9604)]\n"]}],"source":["'''\n","a k-fold cross validation works by splitting the dataset into k folds, training the model on k−1 folds, and testing it on the\n","remaining fold — repeated k times.\n","\n","It means in each of the k iterations of fresh model training,\n","Let:\n","  n = total number of samples (rows in the dataset)\n","  k = number of folds\n","\n","Then in each fold:\n","  Test set size ≈ upto round(n / k) depending on the fold (since n may not divide evenly)\n","\n","  Training set size = n - test set size\n","\n","Eg.\n","  if n = 10, and k = 6 folds\n","\n","  test set size ≈ round(10/6) i.e 1.66 -> 2 (upto 2)\n","  train set size ≈ 10 - 2 = 8\n","\n","  | Fold | Test indices | Train indices (rest of them) |\n","  | ---- | ------------ | ---------------------------- |\n","  | 1    |  [0, 1]      |  [2–9]                       |\n","  | 2    |  [2, 3]      |  [0–1, 4–9]                  |\n","  | 3    |  [4, 5]      |  [0–3, 6–9]                  |\n","  | 4    |  [6, 7]      |  [0–5, 8–9]                  |\n","  | 5    |  [8]         |  [0–7, 9]                    |\n","  | 6    |  [9]         |  [0–8]                       |\n","\n","  Since we are using a different training set for validating a trained model (cross validation) in each fold,\n","  hence called k-fold cross validation\n","\n","Importance of k-fold cross validation is to evaluate the accuracy of the model in each fold, to ensure that the model generalizes well\n","to test data in that fold. This strategy gives a robust estimate of model performance by averaging accuracy (or other metrics) across\n","all folds, thereby reducing overfitting and data mismatch risks, provided the dataset is huge (since, huge training set is needed for\n","training) and contains sampled data that is representative of unseen real-world data (used in final model testing).\n","\n","NOTE: cross-validation (CV) can still lead to overfitting if the training data from dataset is not representative of unseen\n","real-world data. CV can fail to detect overfitting caused by this issue, leading to poor model generalization\n","\n","NOTE: Cross-validation should be done before final model training and testing.\n","      Why?\n","      Cross-validation is used during the model development phase to:\n","        -> Evaluate different models or configurations\n","        -> Select the best-performing model and hyperparameters\n","        -> Estimate generalization performance without touching the final test set\n","\n","      Or can run cross-validation after testing, but it is not recommended unless you're doing it for retrospective analysis,\n","      and not for model selection or tuning.\n","\n","NOTE: Cross-validation is done on the training data only, and not using the final test data\n","\n","NOTE: Cross Validation can be done to understand the model's accuracy and not for correctly identifying the precision of the model\n","\n","'''\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from sklearn.datasets import fetch_openml\n","from sklearn.linear_model import SGDClassifier\n","from sklearn.model_selection import cross_val_score, StratifiedKFold\n","from sklearn.base import clone\n","\n","def plot_digit(image_data, label_data):\n","  #plt.imshow(image_data). Note the shape is (784,) which is reduced to one row, it should be reshaped to 28 x 28\n","  image_data = image_data.reshape(28, 28)\n","  plt.imshow(image_data, cmap=\"binary\") #black & white\n","  plt.axis(\"off\")\n","  print(\"The below image has label: \"+label_data)\n","\n","\n","def my_cross_validation(model, X_train, Y_train_5, num_of_folds):\n","\n","  skfolds = StratifiedKFold(num_of_folds) #k = 3\n","\n","  # to know the row indices of the inputs and labels from the training set, used in the fold for training the model,\n","  # and to know the row indices of the inputs and labels from the test set, used in the fold for testing the trained model,\n","  for fold_idx, (train_indices, test_indices) in enumerate(skfolds.split(X_train, Y_train_5), 1):\n","      print(f\"Fold {fold_idx}\")\n","      print(\"Train indices:\", train_indices)\n","      print(\"Test indices:\", test_indices)\n","      print(\"-\" * 40)\n","\n","  accuracies_in_each_fold = []\n","\n","  for train_indices, test_indices in skfolds.split(X_train, Y_train_5):\n","    clone_model = clone(model) # needs a clone of the model, as the model will be trained from scratch for each fold. Avoids leaking trained parameters between folds.\n","    # Uses the fold indices to slice the original dataset into:\n","\n","    # Training data for this fold\n","    X_train_folds = X_train[train_indices]\n","    Y_train_5_folds = Y_train_5[train_indices]\n","\n","    # Test data for this fold\n","    X_test_fold = X_train[test_indices]\n","    Y_test_5_fold = Y_train_5[test_indices]\n","\n","    # Train the model using the training data for this fold\n","    clone_model.fit(X_train_folds, Y_train_5_folds)\n","\n","    # Test the model using the test data for this fold\n","    y_pred = clone_model.predict(X_test_fold)\n","\n","    accuracy = sum(y_pred == Y_test_5_fold) / len(y_pred)\n","    accuracies_in_each_fold.append(accuracy)\n","\n","  print(accuracies_in_each_fold)\n","\n","\n","if __name__ == \"__main__\":\n","\n","  mnist = fetch_openml('mnist_784', as_frame=False)\n","  '''\n","  with 'as_frame=False\" will return the inputs as 2D numpy array and not pandas dataframe,\n","  and the labels as numpy array and not pandas series\n","  '''\n","  X, Y = mnist.data, mnist.target\n","  print(\"Inputs :\\n\", X.astype(float))\n","  #print(X.shape) # 70000 inputs (rows) x 784 features (columns)\n","  print(\"---------------\")\n","  print(\"Labels :\\n\", Y)\n","  #print(Y.shape) # 70000 labels for inputs\n","\n","  #Showing first input image from the mnist dataset\n","  #plot_digit(X[0], Y[0])\n","\n","  # Splitting the dataset for train and test (85% train & 14% test)\n","  X_train, Y_train, X_test, Y_test = X[:60000], Y[:60000], X[60000:], Y[60000:]\n","\n","  # Training a Binary classfier (classifies numbers if its a '5' or not)\n","  test_data = X_test[0] # Some data from the MNIST testing set\n","  test_data_label = Y_test[0]\n","  Y_train_5 = (Y_train == '5') # True for all 5s, False for other digits\n","  #print(Y_train_5)\n","  Y_test_5 = (Y_test == '5')\n","  model = SGDClassifier(random_state=42)\n","  cloned_model = clone(model)\n","\n","  model.fit(X_train, Y_train_5)\n","\n","  #plot_digit(test_data, test_data_label)\n","  y_pred = model.predict(X_test)\n","  print(y_pred)\n","\n","  # Performing k-fold cross validation (k=3) using sklearn's cross_val_score\n","  #cross_val_score(model, X_train, Y_train_5, cv=3, scoring=\"accuracy\") # array([0.95035, 0.96035, 0.9604 ]) Good Accuracy in each fold!\n","\n","  # Performing k-fold cross validation (k=3) using custom implementation\n","  my_cross_validation(cloned_model, X_train, Y_train_5, num_of_folds=3)\n","\n"]}]}